name: LlamaDart
description: "Supercharge your app with offline AI capabilities, powered by llama.cpp."
output: 'lib/llama_dart.dart'
headers:
  entry-points:
    - 'src/llama_cpp/llama.h'
    - 'src/llama_cpp/ggml.h'  # Add this if ggml_context is defined here
    - 'src/llama_cpp/ggml-*.h'  # Add this if ggml_context is defined here
    - 'src/llama_cpp/k_quants.h'  # Add this if ggml_context is defined here
    - 'src/llama_cpp/common/*.h'  # Add this if ggml_context is defined here
exclude-all-by-default: false
# functions:
#   leaf:
#     include:
#       - '.*'
structs:
  rename:
    '_*(.*)': '$1'
globals:
  rename:
    '_*(.*)': '$1'
preamble: |
  // ignore_for_file: always_specify_types
  // ignore_for_file: camel_case_types
  // ignore_for_file: non_constant_identifier_names
comments:
  style: any
  length: full
compiler-opts-automatic:
  macos:
    include-c-standard-library: true
compiler-opts:
  - '-Wno-nullability-completeness'
